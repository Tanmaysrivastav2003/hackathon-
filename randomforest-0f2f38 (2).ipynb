{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7282058,"sourceType":"datasetVersion","datasetId":4222368}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-03T12:41:17.350096Z","iopub.execute_input":"2024-01-03T12:41:17.350531Z","iopub.status.idle":"2024-01-03T12:41:17.908191Z","shell.execute_reply.started":"2024-01-03T12:41:17.350497Z","shell.execute_reply":"2024-01-03T12:41:17.906919Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset/credit-debit dataset.csv\n/kaggle/input/dataset/TransactionDataset1.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, MultiLabelBinarizer\nfrom sklearn.impute import SimpleImputer\nimport joblib\n\n# Load datasets\ndata1 = pd.read_csv('/kaggle/input/dataset/TransactionDataset1.csv').drop(['user_id', 'name', 'addresses', 'email_address', 'transaction_id', 'transaction_date'], axis=1)\ndata2 = pd.read_csv('/kaggle/input/dataset/credit-debit dataset.csv').dropna()\n\n# Label encoding for categorical variables in data1\nlabel_encoder = LabelEncoder()\ndata1[data1.select_dtypes(include=['object']).columns] = data1.select_dtypes(include=['object']).apply(label_encoder.fit_transform)\n\n# One-hot encoding for categorical variables in data2\ndata2_one_hot = pd.get_dummies(data2, columns=['Employment Status', 'Education Level', 'Marital Status'], drop_first=True)\n\n# One-hot encoding for accounts in data2\nmlb = MultiLabelBinarizer()\ndata2_one_hot = pd.concat([data2_one_hot, pd.DataFrame(mlb.fit_transform(data2_one_hot['Money Sources']), columns=mlb.classes_, index=data2_one_hot.index),\n                   pd.DataFrame(mlb.fit_transform(data2_one_hot['Transfer Accounts']), columns=mlb.classes_, index=data2_one_hot.index)], axis=1)\ndata2_one_hot = data2_one_hot.drop(['Money Sources', 'Transfer Accounts'], axis=1)\n\n# Combine datasets\nX_combined = pd.concat([data1.drop('fraud_indicator', axis=1), data2_one_hot[['Total Credit Amount', 'Transaction Amount']] + data2_one_hot.drop(['Total Credit Amount', 'Transaction Amount', 'Fraud Indicator'], axis=1)], axis=1)\ny_combined = pd.concat([data1['fraud_indicator'], data2_one_hot['Fraud Indicator']], ignore_index=True)[:X_combined.shape[0]]\n\n# Save column names before SimpleImputer transformation\ncolumn_names = X_combined.columns.tolist()\n\n# Split the combined data into training and testing sets\nX_train_combined, X_test_combined, y_train_combined, y_test_combined = train_test_split(\n    X_combined, y_combined, test_size=0.2, random_state=42\n)\n\n# Use SimpleImputer to handle missing values by filling NaNs with the mean\nimputer = SimpleImputer(strategy='mean')\nX_train_combined = imputer.fit_transform(X_train_combined)\nX_test_combined = imputer.transform(X_test_combined)\n\n# Standardize the features\nscaler_combined = StandardScaler()\nX_train_combined = scaler_combined.fit_transform(X_train_combined)\nX_test_combined = scaler_combined.transform(X_test_combined)\n\n# Choose a model (Random Forest)\nmodel_combined = RandomForestClassifier(n_estimators=2000, random_state=42, verbose=1)\n\n# Train the combined model\nmodel_combined.fit(X_train_combined, y_train_combined)\n\n# Make predictions on the test set\ny_pred_combined = model_combined.predict(X_test_combined)\n\n# Display the parameters of the trained RandomForestClassifier\nprint(\"Trained RandomForestClassifier Parameters:\")\nprint(model_combined.get_params())\n\n# Display confusion matrix and classification report\nconf_matrix = confusion_matrix(y_test_combined, y_pred_combined)\nclassification_rep = classification_report(y_test_combined, y_pred_combined)\n\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_rep)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T12:41:25.582808Z","iopub.execute_input":"2024-01-03T12:41:25.584322Z","iopub.status.idle":"2024-01-03T12:42:25.997354Z","shell.execute_reply.started":"2024-01-03T12:41:25.584263Z","shell.execute_reply":"2024-01-03T12:42:25.996007Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.3s\n[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    5.5s\n[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   12.2s\n[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:   21.8s\n[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:   33.9s\n[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:   49.1s\n[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.3s\n[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.7s\n","output_type":"stream"},{"name":"stdout","text":"Trained RandomForestClassifier Parameters:\n{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 2000, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 1, 'warm_start': False}\nConfusion Matrix:\n[[2562    0]\n [ 118 1320]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98      2562\n           1       1.00      0.92      0.96      1438\n\n    accuracy                           0.97      4000\n   macro avg       0.98      0.96      0.97      4000\nweighted avg       0.97      0.97      0.97      4000\n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.1s\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Save the combined model and features\ncombined_model_filename = '/kaggle/working/random_forest_fraud_pred.pkl'\njoblib.dump({\n    'label_encoder': label_encoder,\n    'scaler': scaler_combined,\n    'model': model_combined,\n    'features': column_names  # Save the features used for training\n}, combined_model_filename)\nprint(f'Combined model and features saved as {combined_model_filename}')\n\n# Load the saved model\nloaded_model = joblib.load('/kaggle/working/random_forest_fraud_pred.pkl')\n\n# Display the features on which the model has been trained\nprint(\"Features used for training:\")\nprint(loaded_model['features'])","metadata":{"execution":{"iopub.status.busy":"2024-01-03T12:42:43.739961Z","iopub.execute_input":"2024-01-03T12:42:43.740435Z","iopub.status.idle":"2024-01-03T12:42:47.291933Z","shell.execute_reply.started":"2024-01-03T12:42:43.740399Z","shell.execute_reply":"2024-01-03T12:42:47.290526Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Combined model and features saved as /kaggle/working/random_forest_fraud_pred.pkl\nFeatures used for training:\n['age', 'kyc_status', 'days_since_kyc_incomplete', 'transaction_amount', 'home_branch', 'transaction_location', 'transaction_method', 'transaction_category', 'transaction_merchant', 'transaction_time', 'average_expenditure', 'comparison_with_avg_expenditure', 'transaction_count_7_days', 'suspicion_indicator', ' ', ' ', \"'\", \"'\", ',', ',', '0', '0', '1', '1', '2', '2', '3', '3', '4', '4', '5', '5', '6', '6', '7', '7', '8', '8', '9', '9', 'Education Level_High School', 'Education Level_Master', 'Education Level_PhD', 'Employment Status_Student', 'Employment Status_Unemployed', 'Linked Accounts', 'Marital Status_Married', 'Marital Status_Single', 'Name', 'Total Credit Amount', 'Transaction Amount', 'User ID', '[', '[', ']', ']']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-01-03T11:34:24.406266Z","iopub.execute_input":"2024-01-03T11:34:24.407362Z","iopub.status.idle":"2024-01-03T11:34:24.414583Z","shell.execute_reply.started":"2024-01-03T11:34:24.407317Z","shell.execute_reply":"2024-01-03T11:34:24.412988Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-01-03T12:41:03.428706Z","iopub.execute_input":"2024-01-03T12:41:03.429787Z","iopub.status.idle":"2024-01-03T12:41:03.497449Z","shell.execute_reply.started":"2024-01-03T12:41:03.429744Z","shell.execute_reply":"2024-01-03T12:41:03.496352Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Internet connection is available.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Install Streamlit\n!pip install streamlit\n\n# Load necessary libraries\nimport streamlit as st\nimport joblib\n\n# Load your machine learning model\nmodel = joblib.load('/kaggle/working/random_forest_fraud_pred.pkl')\n\n# Create the Streamlit app\nst.title('Rajasthan Hackhathon')\n\n# Add user input components\nuser_input = st.text_input('Enter some text:')\nprediction_button = st.button('Get Prediction')\n\n# Make predictions\nif prediction_button:\n    prediction = model.predict([user_input])[0]\n    st.write('Prediction:', prediction)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-03T13:00:06.068735Z","iopub.execute_input":"2024-01-03T13:00:06.069179Z","iopub.status.idle":"2024-01-03T13:00:22.406514Z","shell.execute_reply.started":"2024-01-03T13:00:06.069136Z","shell.execute_reply":"2024-01-03T13:00:22.405100Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Requirement already satisfied: streamlit in /opt/conda/lib/python3.10/site-packages (1.29.0)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.2.0)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.7.0)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.2.4)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\nRequirement already satisfied: importlib-metadata<7,>=1.4 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.8.0)\nRequirement already satisfied: numpy<2,>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.24.3)\nRequirement already satisfied: packaging<24,>=16.8 in /opt/conda/lib/python3.10/site-packages (from streamlit) (21.3)\nRequirement already satisfied: pandas<3,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.0.3)\nRequirement already satisfied: pillow<11,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (10.1.0)\nRequirement already satisfied: protobuf<5,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=6.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (14.0.1)\nRequirement already satisfied: python-dateutil<3,>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.8.2)\nRequirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.31.0)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.5.2)\nRequirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.2.3)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.5.0)\nRequirement already satisfied: tzlocal<6,>=1.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.2)\nRequirement already satisfied: validators<1,>=0.2 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.22.0)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.32)\nRequirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.8.1b0)\nRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.3.3)\nRequirement already satisfied: watchdog>=2.1.5 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.0.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.19.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.10)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.16.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<24,>=16.8->streamlit) (3.0.9)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.9.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-12-30T19:59:16.30261Z","iopub.execute_input":"2023-12-30T19:59:16.303665Z","iopub.status.idle":"2023-12-30T19:59:17.180698Z","shell.execute_reply.started":"2023-12-30T19:59:16.303624Z","shell.execute_reply":"2023-12-30T19:59:17.179845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2023-12-30T20:12:30.476297Z","iopub.execute_input":"2023-12-30T20:12:30.476984Z","iopub.status.idle":"2023-12-30T20:13:26.427014Z","shell.execute_reply.started":"2023-12-30T20:12:30.476947Z","shell.execute_reply":"2023-12-30T20:13:26.425763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}